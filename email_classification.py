# -*- coding: utf-8 -*-
"""Email Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11hD1YcatTpFDEPMTzE3mbTXK7D6cHsM4
"""

import pandas as pd
import numpy as np
data=pd.read_csv('spam.csv')
data

data.columns

data.info()

data.isna().sum()

data['Spam']=data['Category'].apply(lambda x:1 if x=='spam' else 0)
data.head(5)

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(data.Message,data.Spam,test_size=0.25)

#CounterVectorizer Convert the text into matrics
from sklearn.feature_extraction.text import CountVectorizer

from sklearn.naive_bayes import MultinomialNB

from sklearn.pipeline import Pipeline
clf=Pipeline([
    ('vectorizer',CountVectorizer()),
    ('nb',MultinomialNB())
])

#'Sounds great! Are you home now?',
    'Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES'
#I hope this email finds you well. Attached please find the document you requested. Let me know if you need any further assistance.

Best regards,
[Your Name]

# Get input from the user
user_input = input("Enter the email message: ")

# Make prediction
prediction = clf.predict([user_input])

# Output the prediction
if prediction[0] == 1:
    print("This email is classified as SPAM.")
else:
    print("This email is classified as NOT SPAM.")

import matplotlib.pyplot as plt

# Visualizing the distribution of spam and non-spam messages
plt.figure(figsize=(6, 4))
data['Category'].value_counts().plot(kind='bar', color=['blue', 'red'])
plt.title('Distribution of Spam vs Non-Spam Messages')
plt.xlabel('Category')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.show()

import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.metrics import confusion_matrix
import seaborn as sns

# Load data
data = pd.read_csv('spam.csv')

# Add 'Spam' column
data['Spam'] = data['Category'].apply(lambda x: 1 if x == 'spam' else 0)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(data.Message, data.Spam, test_size=0.25)

# Naive Bayes Classifier Pipeline
clf = Pipeline([
    ('vectorizer', CountVectorizer()),
    ('nb', MultinomialNB())
])
clf.fit(X_train, y_train)

# Visualization
# Word Cloud for spam messages
spam_words = ' '.join(list(data[data['Category'] == 'spam']['Message']))
if len(spam_words) > 0:
    spam_wordcloud = WordCloud(width=800, height=400).generate(spam_words)

    plt.figure(figsize=(10, 6))
    plt.imshow(spam_wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud for Spam Messages')
    plt.show()

# Word Cloud for non-spam messages
ham_words = ' '.join(list(data[data['Category'] == 'ham']['Message']))
if len(ham_words) > 0:
    ham_wordcloud = WordCloud(width=800, height=400).generate(ham_words)

    plt.figure(figsize=(10, 6))
    plt.imshow(ham_wordcloud, interpolation='bilinear')
    plt.axis('off')
    plt.title('Word Cloud for Non-Spam Messages')
    plt.show()

# Confusion Matrix
y_pred = clf.predict(X_test)
conf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap="Blues",
            xticklabels=['Non-Spam', 'Spam'],
            yticklabels=['Non-Spam', 'Spam'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Length of Messages
data['Message_Length'] = data['Message'].apply(len)
plt.figure(figsize=(10, 6))
data[data['Category'] == 'ham']['Message_Length'].plot(bins=35, kind='hist', color='blue',
                                                      label='Non-Spam', alpha=0.6)
data[data['Category'] == 'spam']['Message_Length'].plot(bins=35, kind='hist', color='red',
                                                       label='Spam', alpha=0.6)
plt.legend()
plt.xlabel("Message Length")
plt.title('Distribution of Message Length')
plt.show()

emails=[
    'Sounds great! Are you home now?',
    'Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES'
]

clf.predict(emails)

clf.fit(X_train,y_train)

clf.score(X_test,y_test)